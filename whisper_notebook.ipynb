{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Whisper Notes\n",
    "\n",
    "This notebook is intended to be used to explore the whisper api by openai"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Requirements"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "G:\\My Drive\\07 - Dev\\github\\drbothen\\whisper_notes\\venv\\lib\\site-packages\\whisper\\timing.py:58: NumbaDeprecationWarning: \u001B[1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\u001B[0m\n",
      "  def backtrace(trace: np.ndarray):\n"
     ]
    }
   ],
   "source": [
    "import openai\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import scipy\n",
    "from scipy import stats\n",
    "from tabulate import tabulate\n",
    "from dotenv import load_dotenv\n",
    "import sys\n",
    "import os\n",
    "from pydub import AudioSegment\n",
    "import whisper"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-14T23:11:04.168361300Z",
     "start_time": "2023-06-14T23:10:14.623948Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Versions"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "╒════════════╤══════════════════════════════════════════════════════════════════════════════════╕\n",
      "│ Module     │ Version                                                                          │\n",
      "╞════════════╪══════════════════════════════════════════════════════════════════════════════════╡\n",
      "│ numpy      │ 1.24.3                                                                           │\n",
      "├────────────┼──────────────────────────────────────────────────────────────────────────────────┤\n",
      "│ panda      │ 2.0.2                                                                            │\n",
      "├────────────┼──────────────────────────────────────────────────────────────────────────────────┤\n",
      "│ matplotlib │ 3.7.1                                                                            │\n",
      "├────────────┼──────────────────────────────────────────────────────────────────────────────────┤\n",
      "│ seaborn    │ 0.12.2                                                                           │\n",
      "├────────────┼──────────────────────────────────────────────────────────────────────────────────┤\n",
      "│ scipy      │ 1.10.1                                                                           │\n",
      "├────────────┼──────────────────────────────────────────────────────────────────────────────────┤\n",
      "│ openai     │ 0.27.7                                                                           │\n",
      "├────────────┼──────────────────────────────────────────────────────────────────────────────────┤\n",
      "│ whisper    │ 20230314                                                                         │\n",
      "├────────────┼──────────────────────────────────────────────────────────────────────────────────┤\n",
      "│ python     │ 3.10.4 (tags/v3.10.4:9d38120, Mar 23 2022, 23:13:41) [MSC v.1929 64 bit (AMD64)] │\n",
      "╘════════════╧══════════════════════════════════════════════════════════════════════════════════╛\n"
     ]
    }
   ],
   "source": [
    "versions = {\n",
    "    'numpy': np.__version__,\n",
    "    'panda': pd.__version__,\n",
    "    'matplotlib': matplotlib._get_version(),\n",
    "    'seaborn': sns.__version__,\n",
    "    'scipy': scipy.__version__,\n",
    "    'openai': openai.__version__,\n",
    "    'whisper': whisper.__version__,\n",
    "    'python': sys.version\n",
    "}\n",
    "\n",
    "table = tabulate(\n",
    "    versions.items(),\n",
    "    headers=[\"Module\", \"Version\"],\n",
    "    tablefmt=\"fancy_grid\",\n",
    ")\n",
    "\n",
    "print(table)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-14T23:11:04.252895400Z",
     "start_time": "2023-06-14T23:11:04.122294400Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Globals"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Import ENV"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "True"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv() # Loads .env file into env vars"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-14T23:11:04.351689700Z",
     "start_time": "2023-06-14T23:11:04.159624100Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Assignments"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "openai_api_key = os.getenv('OPENAI_API_KEY')\n",
    "audio_file_path = \"G:\\\\My Drive\\\\03 - Work\\\\03.03 - Meetings\\\\03.03.05 - Inbox\\\\MSS - Keyhole - Sync Meeting with Steve over Ticketing V2 - 06.14.2023.flac\"\n",
    "openai.api_key = openai_api_key"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-15T01:05:35.873986500Z",
     "start_time": "2023-06-15T01:05:35.852938200Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Investigate Audio File"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "audio = AudioSegment.from_file(audio_file_path, \"flac\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-15T01:05:47.584643Z",
     "start_time": "2023-06-15T01:05:41.569026900Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "audio file is 71.0 Minutes long\n"
     ]
    }
   ],
   "source": [
    "print(\"audio file is \" + str(audio.duration_seconds // 60) + \" Minutes long\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-15T01:05:47.810217800Z",
     "start_time": "2023-06-15T01:05:47.799134200Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## OpenAI Web API Whisper"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Get the transcript"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[14], line 2\u001B[0m\n\u001B[0;32m      1\u001B[0m audio_file \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mopen\u001B[39m(audio_file_path, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mrb\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m----> 2\u001B[0m transcript \u001B[38;5;241m=\u001B[39m \u001B[43mopenai\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mAudio\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtranslate\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mwhisper-1\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43maudio_file\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mG:\\My Drive\\07 - Dev\\github\\drbothen\\whisper_notes\\venv\\lib\\site-packages\\openai\\api_resources\\audio.py:92\u001B[0m, in \u001B[0;36mAudio.translate\u001B[1;34m(cls, model, file, api_key, api_base, api_type, api_version, organization, **params)\u001B[0m\n\u001B[0;32m     82\u001B[0m requestor, files, data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mcls\u001B[39m\u001B[38;5;241m.\u001B[39m_prepare_request(\n\u001B[0;32m     83\u001B[0m     file\u001B[38;5;241m=\u001B[39mfile,\n\u001B[0;32m     84\u001B[0m     filename\u001B[38;5;241m=\u001B[39mfile\u001B[38;5;241m.\u001B[39mname,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m     89\u001B[0m     \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mparams,\n\u001B[0;32m     90\u001B[0m )\n\u001B[0;32m     91\u001B[0m url \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mcls\u001B[39m\u001B[38;5;241m.\u001B[39m_get_url(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtranslations\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m---> 92\u001B[0m response, _, api_key \u001B[38;5;241m=\u001B[39m \u001B[43mrequestor\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrequest\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mpost\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43murl\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfiles\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mfiles\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mparams\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdata\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     93\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m util\u001B[38;5;241m.\u001B[39mconvert_to_openai_object(\n\u001B[0;32m     94\u001B[0m     response, api_key, api_version, organization\n\u001B[0;32m     95\u001B[0m )\n",
      "File \u001B[1;32mG:\\My Drive\\07 - Dev\\github\\drbothen\\whisper_notes\\venv\\lib\\site-packages\\openai\\api_requestor.py:220\u001B[0m, in \u001B[0;36mAPIRequestor.request\u001B[1;34m(self, method, url, params, headers, files, stream, request_id, request_timeout)\u001B[0m\n\u001B[0;32m    209\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mrequest\u001B[39m(\n\u001B[0;32m    210\u001B[0m     \u001B[38;5;28mself\u001B[39m,\n\u001B[0;32m    211\u001B[0m     method,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    218\u001B[0m     request_timeout: Optional[Union[\u001B[38;5;28mfloat\u001B[39m, Tuple[\u001B[38;5;28mfloat\u001B[39m, \u001B[38;5;28mfloat\u001B[39m]]] \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[0;32m    219\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Tuple[Union[OpenAIResponse, Iterator[OpenAIResponse]], \u001B[38;5;28mbool\u001B[39m, \u001B[38;5;28mstr\u001B[39m]:\n\u001B[1;32m--> 220\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrequest_raw\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    221\u001B[0m \u001B[43m        \u001B[49m\u001B[43mmethod\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mlower\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    222\u001B[0m \u001B[43m        \u001B[49m\u001B[43murl\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    223\u001B[0m \u001B[43m        \u001B[49m\u001B[43mparams\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mparams\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    224\u001B[0m \u001B[43m        \u001B[49m\u001B[43msupplied_headers\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mheaders\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    225\u001B[0m \u001B[43m        \u001B[49m\u001B[43mfiles\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mfiles\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    226\u001B[0m \u001B[43m        \u001B[49m\u001B[43mstream\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mstream\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    227\u001B[0m \u001B[43m        \u001B[49m\u001B[43mrequest_id\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mrequest_id\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    228\u001B[0m \u001B[43m        \u001B[49m\u001B[43mrequest_timeout\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mrequest_timeout\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    229\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    230\u001B[0m     resp, got_stream \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_interpret_response(result, stream)\n\u001B[0;32m    231\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m resp, got_stream, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mapi_key\n",
      "File \u001B[1;32mG:\\My Drive\\07 - Dev\\github\\drbothen\\whisper_notes\\venv\\lib\\site-packages\\openai\\api_requestor.py:520\u001B[0m, in \u001B[0;36mAPIRequestor.request_raw\u001B[1;34m(self, method, url, params, supplied_headers, files, stream, request_id, request_timeout)\u001B[0m\n\u001B[0;32m    518\u001B[0m     _thread_context\u001B[38;5;241m.\u001B[39msession \u001B[38;5;241m=\u001B[39m _make_session()\n\u001B[0;32m    519\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m--> 520\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[43m_thread_context\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msession\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrequest\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    521\u001B[0m \u001B[43m        \u001B[49m\u001B[43mmethod\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    522\u001B[0m \u001B[43m        \u001B[49m\u001B[43mabs_url\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    523\u001B[0m \u001B[43m        \u001B[49m\u001B[43mheaders\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mheaders\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    524\u001B[0m \u001B[43m        \u001B[49m\u001B[43mdata\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdata\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    525\u001B[0m \u001B[43m        \u001B[49m\u001B[43mfiles\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mfiles\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    526\u001B[0m \u001B[43m        \u001B[49m\u001B[43mstream\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mstream\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    527\u001B[0m \u001B[43m        \u001B[49m\u001B[43mtimeout\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mrequest_timeout\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mif\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mrequest_timeout\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01melse\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mTIMEOUT_SECS\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    528\u001B[0m \u001B[43m        \u001B[49m\u001B[43mproxies\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m_thread_context\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msession\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mproxies\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    529\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    530\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m requests\u001B[38;5;241m.\u001B[39mexceptions\u001B[38;5;241m.\u001B[39mTimeout \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[0;32m    531\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m error\u001B[38;5;241m.\u001B[39mTimeout(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mRequest timed out: \u001B[39m\u001B[38;5;132;01m{}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;241m.\u001B[39mformat(e)) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01me\u001B[39;00m\n",
      "File \u001B[1;32mG:\\My Drive\\07 - Dev\\github\\drbothen\\whisper_notes\\venv\\lib\\site-packages\\requests\\sessions.py:589\u001B[0m, in \u001B[0;36mSession.request\u001B[1;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001B[0m\n\u001B[0;32m    584\u001B[0m send_kwargs \u001B[38;5;241m=\u001B[39m {\n\u001B[0;32m    585\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtimeout\u001B[39m\u001B[38;5;124m\"\u001B[39m: timeout,\n\u001B[0;32m    586\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mallow_redirects\u001B[39m\u001B[38;5;124m\"\u001B[39m: allow_redirects,\n\u001B[0;32m    587\u001B[0m }\n\u001B[0;32m    588\u001B[0m send_kwargs\u001B[38;5;241m.\u001B[39mupdate(settings)\n\u001B[1;32m--> 589\u001B[0m resp \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msend(prep, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39msend_kwargs)\n\u001B[0;32m    591\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m resp\n",
      "File \u001B[1;32mG:\\My Drive\\07 - Dev\\github\\drbothen\\whisper_notes\\venv\\lib\\site-packages\\requests\\sessions.py:703\u001B[0m, in \u001B[0;36mSession.send\u001B[1;34m(self, request, **kwargs)\u001B[0m\n\u001B[0;32m    700\u001B[0m start \u001B[38;5;241m=\u001B[39m preferred_clock()\n\u001B[0;32m    702\u001B[0m \u001B[38;5;66;03m# Send the request\u001B[39;00m\n\u001B[1;32m--> 703\u001B[0m r \u001B[38;5;241m=\u001B[39m adapter\u001B[38;5;241m.\u001B[39msend(request, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m    705\u001B[0m \u001B[38;5;66;03m# Total elapsed time of the request (approximately)\u001B[39;00m\n\u001B[0;32m    706\u001B[0m elapsed \u001B[38;5;241m=\u001B[39m preferred_clock() \u001B[38;5;241m-\u001B[39m start\n",
      "File \u001B[1;32mG:\\My Drive\\07 - Dev\\github\\drbothen\\whisper_notes\\venv\\lib\\site-packages\\requests\\adapters.py:486\u001B[0m, in \u001B[0;36mHTTPAdapter.send\u001B[1;34m(self, request, stream, timeout, verify, cert, proxies)\u001B[0m\n\u001B[0;32m    483\u001B[0m     timeout \u001B[38;5;241m=\u001B[39m TimeoutSauce(connect\u001B[38;5;241m=\u001B[39mtimeout, read\u001B[38;5;241m=\u001B[39mtimeout)\n\u001B[0;32m    485\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m--> 486\u001B[0m     resp \u001B[38;5;241m=\u001B[39m \u001B[43mconn\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43murlopen\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    487\u001B[0m \u001B[43m        \u001B[49m\u001B[43mmethod\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mrequest\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmethod\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    488\u001B[0m \u001B[43m        \u001B[49m\u001B[43murl\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43murl\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    489\u001B[0m \u001B[43m        \u001B[49m\u001B[43mbody\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mrequest\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbody\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    490\u001B[0m \u001B[43m        \u001B[49m\u001B[43mheaders\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mrequest\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mheaders\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    491\u001B[0m \u001B[43m        \u001B[49m\u001B[43mredirect\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[0;32m    492\u001B[0m \u001B[43m        \u001B[49m\u001B[43massert_same_host\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[0;32m    493\u001B[0m \u001B[43m        \u001B[49m\u001B[43mpreload_content\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[0;32m    494\u001B[0m \u001B[43m        \u001B[49m\u001B[43mdecode_content\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[0;32m    495\u001B[0m \u001B[43m        \u001B[49m\u001B[43mretries\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmax_retries\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    496\u001B[0m \u001B[43m        \u001B[49m\u001B[43mtimeout\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtimeout\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    497\u001B[0m \u001B[43m        \u001B[49m\u001B[43mchunked\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mchunked\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    498\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    500\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m (ProtocolError, \u001B[38;5;167;01mOSError\u001B[39;00m) \u001B[38;5;28;01mas\u001B[39;00m err:\n\u001B[0;32m    501\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mConnectionError\u001B[39;00m(err, request\u001B[38;5;241m=\u001B[39mrequest)\n",
      "File \u001B[1;32mG:\\My Drive\\07 - Dev\\github\\drbothen\\whisper_notes\\venv\\lib\\site-packages\\urllib3\\connectionpool.py:790\u001B[0m, in \u001B[0;36mHTTPConnectionPool.urlopen\u001B[1;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001B[0m\n\u001B[0;32m    787\u001B[0m response_conn \u001B[38;5;241m=\u001B[39m conn \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m release_conn \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m    789\u001B[0m \u001B[38;5;66;03m# Make the request on the HTTPConnection object\u001B[39;00m\n\u001B[1;32m--> 790\u001B[0m response \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_make_request(\n\u001B[0;32m    791\u001B[0m     conn,\n\u001B[0;32m    792\u001B[0m     method,\n\u001B[0;32m    793\u001B[0m     url,\n\u001B[0;32m    794\u001B[0m     timeout\u001B[38;5;241m=\u001B[39mtimeout_obj,\n\u001B[0;32m    795\u001B[0m     body\u001B[38;5;241m=\u001B[39mbody,\n\u001B[0;32m    796\u001B[0m     headers\u001B[38;5;241m=\u001B[39mheaders,\n\u001B[0;32m    797\u001B[0m     chunked\u001B[38;5;241m=\u001B[39mchunked,\n\u001B[0;32m    798\u001B[0m     retries\u001B[38;5;241m=\u001B[39mretries,\n\u001B[0;32m    799\u001B[0m     response_conn\u001B[38;5;241m=\u001B[39mresponse_conn,\n\u001B[0;32m    800\u001B[0m     preload_content\u001B[38;5;241m=\u001B[39mpreload_content,\n\u001B[0;32m    801\u001B[0m     decode_content\u001B[38;5;241m=\u001B[39mdecode_content,\n\u001B[0;32m    802\u001B[0m     \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mresponse_kw,\n\u001B[0;32m    803\u001B[0m )\n\u001B[0;32m    805\u001B[0m \u001B[38;5;66;03m# Everything went great!\u001B[39;00m\n\u001B[0;32m    806\u001B[0m clean_exit \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n",
      "File \u001B[1;32mG:\\My Drive\\07 - Dev\\github\\drbothen\\whisper_notes\\venv\\lib\\site-packages\\urllib3\\connectionpool.py:536\u001B[0m, in \u001B[0;36mHTTPConnectionPool._make_request\u001B[1;34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001B[0m\n\u001B[0;32m    534\u001B[0m \u001B[38;5;66;03m# Receive the response from the server\u001B[39;00m\n\u001B[0;32m    535\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m--> 536\u001B[0m     response \u001B[38;5;241m=\u001B[39m \u001B[43mconn\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mgetresponse\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    537\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m (BaseSSLError, \u001B[38;5;167;01mOSError\u001B[39;00m) \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[0;32m    538\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_raise_timeout(err\u001B[38;5;241m=\u001B[39me, url\u001B[38;5;241m=\u001B[39murl, timeout_value\u001B[38;5;241m=\u001B[39mread_timeout)\n",
      "File \u001B[1;32mG:\\My Drive\\07 - Dev\\github\\drbothen\\whisper_notes\\venv\\lib\\site-packages\\urllib3\\connection.py:454\u001B[0m, in \u001B[0;36mHTTPConnection.getresponse\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    451\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mresponse\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m HTTPResponse\n\u001B[0;32m    453\u001B[0m \u001B[38;5;66;03m# Get the response from http.client.HTTPConnection\u001B[39;00m\n\u001B[1;32m--> 454\u001B[0m httplib_response \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43msuper\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mgetresponse\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    456\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m    457\u001B[0m     assert_header_parsing(httplib_response\u001B[38;5;241m.\u001B[39mmsg)\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\http\\client.py:1374\u001B[0m, in \u001B[0;36mHTTPConnection.getresponse\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m   1372\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m   1373\u001B[0m     \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m-> 1374\u001B[0m         \u001B[43mresponse\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbegin\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1375\u001B[0m     \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mConnectionError\u001B[39;00m:\n\u001B[0;32m   1376\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mclose()\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\http\\client.py:318\u001B[0m, in \u001B[0;36mHTTPResponse.begin\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    316\u001B[0m \u001B[38;5;66;03m# read until we get a non-100 response\u001B[39;00m\n\u001B[0;32m    317\u001B[0m \u001B[38;5;28;01mwhile\u001B[39;00m \u001B[38;5;28;01mTrue\u001B[39;00m:\n\u001B[1;32m--> 318\u001B[0m     version, status, reason \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_read_status\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    319\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m status \u001B[38;5;241m!=\u001B[39m CONTINUE:\n\u001B[0;32m    320\u001B[0m         \u001B[38;5;28;01mbreak\u001B[39;00m\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\http\\client.py:279\u001B[0m, in \u001B[0;36mHTTPResponse._read_status\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    278\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_read_status\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n\u001B[1;32m--> 279\u001B[0m     line \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mstr\u001B[39m(\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfp\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mreadline\u001B[49m\u001B[43m(\u001B[49m\u001B[43m_MAXLINE\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m+\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m)\u001B[49m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124miso-8859-1\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m    280\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(line) \u001B[38;5;241m>\u001B[39m _MAXLINE:\n\u001B[0;32m    281\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m LineTooLong(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mstatus line\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\socket.py:705\u001B[0m, in \u001B[0;36mSocketIO.readinto\u001B[1;34m(self, b)\u001B[0m\n\u001B[0;32m    703\u001B[0m \u001B[38;5;28;01mwhile\u001B[39;00m \u001B[38;5;28;01mTrue\u001B[39;00m:\n\u001B[0;32m    704\u001B[0m     \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m--> 705\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_sock\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrecv_into\u001B[49m\u001B[43m(\u001B[49m\u001B[43mb\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    706\u001B[0m     \u001B[38;5;28;01mexcept\u001B[39;00m timeout:\n\u001B[0;32m    707\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_timeout_occurred \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\ssl.py:1273\u001B[0m, in \u001B[0;36mSSLSocket.recv_into\u001B[1;34m(self, buffer, nbytes, flags)\u001B[0m\n\u001B[0;32m   1269\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m flags \u001B[38;5;241m!=\u001B[39m \u001B[38;5;241m0\u001B[39m:\n\u001B[0;32m   1270\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[0;32m   1271\u001B[0m           \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mnon-zero flags not allowed in calls to recv_into() on \u001B[39m\u001B[38;5;132;01m%s\u001B[39;00m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;241m%\u001B[39m\n\u001B[0;32m   1272\u001B[0m           \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__class__\u001B[39m)\n\u001B[1;32m-> 1273\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mread\u001B[49m\u001B[43m(\u001B[49m\u001B[43mnbytes\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbuffer\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1274\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m   1275\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28msuper\u001B[39m()\u001B[38;5;241m.\u001B[39mrecv_into(buffer, nbytes, flags)\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\ssl.py:1129\u001B[0m, in \u001B[0;36mSSLSocket.read\u001B[1;34m(self, len, buffer)\u001B[0m\n\u001B[0;32m   1127\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m   1128\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m buffer \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m-> 1129\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_sslobj\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mread\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mlen\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbuffer\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1130\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m   1131\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_sslobj\u001B[38;5;241m.\u001B[39mread(\u001B[38;5;28mlen\u001B[39m)\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "audio_file = open(audio_file_path, \"rb\")\n",
    "transcript = openai.Audio.translate(\"whisper-1\", audio_file)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-08T21:43:10.613809600Z",
     "start_time": "2023-06-08T21:42:52.428139300Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(transcript)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## local Whisper Python API"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Load Model\n",
    "\n",
    "Available models:\n",
    "- tiny\n",
    "- base\n",
    "- small\n",
    "- medium\n",
    "- large"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "model = whisper.load_model(\"base\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-15T02:26:04.686853300Z",
     "start_time": "2023-06-15T02:26:04.009884900Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Load Audio & Transcribe"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "G:\\My Drive\\07 - Dev\\github\\drbothen\\whisper_notes\\venv\\lib\\site-packages\\whisper\\transcribe.py:114: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
      "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " What you're saying about that because I looked into and file is a new Project for me too that it You know it kind of does want to wire at like you know and at an application love right like you're saying as a standalone How does it work well with integration? Right, you know just just as a library, you know, right? Yeah, we're just using it standalone I haven't used it in that capacity before I do think it's the best fit for Because it simplifies a lot if you're building like a standalone application like my connect like basically my connector is And so I don't what I what I what I hate doing is putting you guys in a box Right because then then we can end up with a fucked up solution and that's not that's not what I want Use the best tool for the for the job and there's other libraries And so don't be afraid to look at those just because we're we're I'm using files for what I'm doing It just happens to be the right tool for what I'm using using it sure sure and they're and they're plenty of odd There are plenty of like you know Kafka, you know first rate from you know Apache I So you're right it may turn out to be you know just just use Something that expects itself to just you know really just kind of be isolated as I see what you're saying You're used so sounds like you used files on the GRSM project there and That makes sense because it you know, it's it's doing one thing right? It's right. You're querying the In whatever fashion, you know, you're querying the GRSM and you're putting it into a topic so okay, that's good to know Now and so you're in second bit for your second bit There will be when when my connector initially launches like because and I and I have to plan for for the services to To reboot and all that stuff we try it work We're trying to plan around as much as as we can with our we're assuming that our services are a federal right so that They can be destroyed and restarted at any point and so the Kafka connectors no different so on its first launch Yes, there's a process that I'm working through a workflow that it'll probably go and query using the rest API But then after that it sets up a web a web hook listener and so I can point Gira SM at a web hook which will be my connector and in any time any of the analysts all can list make any changes to the tickets We'll just get notified so I don't have to constantly yeah, you know more right all the tickets right right right you're more stream processing You're you know Published or pub something No request why Okay, and then on that note then like let's talk I mean and Something I forgot to write down but but you're From your side are you you know Oh And then just so you know too what you what you see in this initial V1 plugin Tickets was meant to give Krima enough stuff to mock. I think there's a lot of stuff there You're gonna reuse because we're still gonna save stuff to a database and that's basically what it's doing But you're just you're adding in the Kafka bit So so you know it's pretty lean in mean and no caffeine here on this this project here Like I said looks like you're you're pulling off a git hash From something. Oh, yeah, that's a version. That's just for version information. That's all that is Right, you know it really doesn't even work once you're compiled I say compiled that's not the right word but once it's built and it's out of the git Right, you no longer you no longer get any and stuff and so that probably shouldn't even be in there What that that version file that you see is is out of my snippet library, right? I I add a since we're compiling that compiling it's not the right word since we're putting this into a Python library I like to include a way to pull version information off of it And so what you're seeing is the snippet that I dump into all my libraries But in this particular case once it's a plug-in that git hash doesn't actually work But but it doesn't also break anything either so but it did this just file that you're looking in is solely to pipe out the version information So like if so if you're wanting to make sure and check the versions that are installed Or you're for some reason wanting to consume this as a library right you can get the version information out So sorry just a little quicker you you mean So in this case would get version you're talking about up the plug-in. Is that right? Yeah of the plug-in? Oh, yeah, yeah Okay, so well then I guess my follow-up is Well, where's the code? You know that you were working off on Oh, yeah, and then I know you In Kafka in the Kafka connector there there is some offline Commits that I have that I haven't necessarily pushed all the way off, but okay being at the bit and just so that you're aware My work comes in like dramatic fits Because I'm a director. I have three other teams that I manage and I'm also Straddled with writing this code, which is why I got finally got permit approval To pull you guys in was to pull this off my plate because I am the only coder on the team Yeah, well I mean I can definitely help you know to take care of that what you'll see though What what you'll see just so you're aware is that you'll come back over a weekend and you'll see massive amounts of pushes Right that haven't had a weekend for me to sit down and just go do that just I This is not made for you to feel bad at all don't take it. I'm just trying to explain the situation I typically put in about 80 hours a week. It's just because I'm I'm over I'm over the three teams. I'm half in the right proposals for us to go and get other work I have a chart issues. I got a manage because I manage people right and so it's just there's just a lot and so coding Tens of four when I get a chance because it's individual contributor work that I don't get a lot to do I spent about four hours in meetings Yeah, no, I yeah, I was told that that was the case I mean that you know get carving out a moment of your time might be you know difficult with Yeah, it's your load and in terms of meetings and stuff Well, I'm not let's let's talk about this. We I mean so listen right I was never going to Effect that project right now, but really what I was looking at. I think you know where I'm getting at is just then You know, what what are you just are you wall pumping? You know like whatever the reply is of a certain Thing here into you know from a reply from one of these into a You know into into a queue and certainly I can make that up with the queue is right now It's not a big deal. Like I said, I may I've made one up local anyway, but I just kind of wanted to know what kind of shape I should expect yeah, 100% and 100% so Fossed has and not not interrupt you there Josh, but is there is there one can we just focus right now like on just one call That you're like, yeah, this is for sure. I'm gonna grab and you know, and then I can just kind of model it from there And then maybe pick up maybe a broader, you know what I mean? It's just a First slice in okay 100% Here if you go to the Gerrit sorry go to the ticket plug-in and then go into the models folder And go in look so so if you see base ticket right obviously if you if you look at that base ticket is just But it's the base that all the models inherit from those tickets though that you see That's at this point in time that's all the information I'm attending this in you across Why inside of what's called a Fossed record which you don't even know what the I mean you need to know what it is But when you receive it, it's not a false record. It's whatever you decide to serialize it into right But I put it into a false record because that's how false works and then I put that record onto the onto the queue Right, and so basically all the detail that you see across all these models Is what you could potentially be receiving? Now there's some small changes coming because Tyler changed some of the fields and so some of that's gonna have to be reflected in these models He decided to concatenate fields together Right so Tyler is the person who I have actually building the the Gira Instance for the saw canless and he decided to concatenate fields together when he was giving me when he did so we went through a planning phase He gave me the fields I built what you see in here to those fields to those fields he gave me They when we went to implement it in real life He's like I don't need all these fields and he can't need it so many other and we I just haven't had a chance to go back and reflect that but But obviously I will I will get that information when I go through and build the record and I will send you the the stuff that needs to be changed But yeah, so basically what you see in those models that's the data that's coming across And and but you're you're So let me say this I should expect to be able to serialize right off the wire If I get if I bring in that message From from from a topic there. I should I get you're saying I should be able to serialize it into one of these You know whatever eight or nine you should be free It shouldn't be a yeah traumatic lift. I would hope if it is and I did maybe I did something wrong I need to go look at how I'm sending that to you, but But yeah, my my my hope is that it's super simple when it when it comes across and we've maybe already got the models and And depending on how easy it is it takes under that's off of Kafka and serialize it into a Django, you know Model, you know, that's that's the part you'll have to work through, but hopefully it's fairly simple And and so kids so it sounds like this base ticket is a base model here So it maybe we could talk just a second about It's fields Up here. Yes, okay, so the clients ID for the Yeah Yeah, client ID might change I think that that probably should have been a UID before but I Modeled it exactly how he gave it to me right and you got to understand Tyler's not a developer a programmer And so he doesn't necessarily think through these things, but in the short amount of time I had because we're dealing with Krima Just you know, there's technical debt that's accumulating in here That I just decided to reflect it verbatim to what he provided to me because that was a quick and dirty to get it out the door And then I noted it in my nose. Okay, I probably need to go change these things because this I don't think will work long term But yes, sorry continue on with your questions, though, and just so you know I will probably after this call I will forward type up some meeting minutes from this and send it over to you Okay The Just one second my side I'm gonna be my director a quick just once I can be right back You You You All right, I'm back. So the So this base ticket is itself just It's just a big really based class Did it be a change comment or change case rather comments health incident a hunt case A miter So some of those are some of those are incorporated in right so I tried to To extrapolate out the fields when we were reusing them in a couple of places We use some fields across tickets, but they but they're not used in all tickets, right? So I included that as a as a separate class And then like change case if you go and pop open change case change case as nothing But that's just because that's how it worked out for what Tyler gave me And so I left it as a placeholder and that way we have a change case so you when you make a change case You just change change case class But it doesn't add anything really except for the class Basically, I'm just looking for you know, you know line six here based on the looking for the classes that Extend basic whatever So so any of those could come by and Well, I'll look you know, you know, it'd be helpful is if you could you said well it's a It's a false record that is that's in the bucket there If maybe I could see what that serialization looks like just so I know Yeah, I got you know because it's probably it's probably embedded in the middle like some because he writes There's gonna be like time stamp and things and you know that kind of stuff So I've got so I've got I've got my scratch notes from when I was learning the the files library Um, I don't mind sharing those with you. So as you don't judge Um So I threw together like a quick uh semi-autical so I I I do Automated trading and stuff like that and so I have a I do a lot of machine learning and stuff like that And so I I started off learning it for that and I'm like oh this actually is a good use case because the use case The I would argue the use cases poor for what we're wanting to use it for Uh for our client portal, but Kafka itself is used as a transport for the entirety of the MSS And so I figured we might as well use it It's there. Let's use it and then we still get the decoupling that we're wanting across all of our applications And that way in the event that we rip and replace geroservice manager in the future, which is a real possibility The idea is hopefully it's not so painful and it hasn't required broad Changes across everything. I just have to change the the one service that's ingesting from our ticketing Um, and then I just serialize it the same way that you're getting it once we figured all that out And then nothing has a change on the main clip You know project, but I will share Some um connectors that I made Unrelated to this that I think might help you understand how those are being sent and received is that is that what I'm gathering Is that like really? I mean that word in your mouth. Yeah Well, no that would certainly help, but I guess what I'm saying is is I understand it um You know You know, it's you know, I'm not just getting the raw JSON value out of the bucket I'm getting it with also other metadata, you know, that's a maybe I'm There's no other data on there unless I put it on there. Oh, okay. Okay. So and I might put more data on there, right? But um, it honestly some of this will evolve as we go through right it I tell it to everybody we're building this airplane is reflining because we weren't given time tables And I don't and I've impacted those time tables as much as I could to give us some room But we're very much building this airplane is reflying it there is loose designs. I had a lot more designs Two years ago um, and then everything changed Uh as uh as our and it's not marks fault But as our BLL changes he's uh he's uh he's who I'm building this for he's technically my customer right at the end of this And so my goal is to try and enable him to be successful. And so our designs really kind of Started with uh with the cloud Infrastructures that we have the client portal wasn't even a thought So client portal was added on and then I really haven't had a whole lot of time to sit down and articulate everything This is just as I try to bring dump things out of my head. That's what you're seeing And unfortunately their symptoms along with that. I'm not naive Um, it's just it's just it's just a situation we're in so I asked to be patient Uh for stuff because some of these stuff we are going to be making decisions on the floor So uh, yeah, it's understood. Yeah, sure sure. Yeah, that's uh Yeah, and I think we were just talking about earlier anyway just like You know, I'm already having questions. I think that you're already you know thinking about and stuff I'm never saying ask away. Yeah TBD TBD type stuff. So uh, that's yeah, that's totally okay So but let me ask you this then yeah So you know finding out what the shape of the uh, you know, that that's the one thing coming out of Well, I mean, that's another thing. Are you? Oh god, I assume or you put you do you have a change case topic? You know, uh health incident topic Hunt case topic. You know, I mean like how are you Uh, well, so initially should I think now? Well, so what I'm thinking right now um Is that I would just put the type in there and we could parse it out on the type and maybe only have one channel And last we get into it and we're like hey man It would really make sense for us to listen on a whole bunch of different you know topics then then maybe we'll go there But I was thinking Simple for right now because I only have until technically the end of the month To get a free one out and you can see we got a lot of work ahead of us I'm not sure it's been terribly credible Uh, don't kill yourself trying to get it done, but you know, obviously no that that's why I was like okay Let's I'm gonna set an arbitrary date of middle and next week for you to get these changes reflected Uh, that's why I'm not sure it's possible Um, but um for now what I was thinking um and I this is up for conversation But what I was initially thinking is just at least for this first release that we're doing a single topic That inside each one of the tickets you'll get the type of ticket it is and then you can parse off of that to know what to do with it And if that doesn't work then yeah, we can change it um and now what that topic name is I'm not sure yet um and some of that also changes because Faust does some auto magical shit For you depending on like um if uh because I first I thought I might need to cash some of this stuff Right, and so if I create a cash to what's called a table right inside of Faust, but it's it's Kafka backed Right, but it's basically a cashed layer of it. Then it create it goes and auto magically creates other topics Um to handle all that stuff with a deterministic name Um, but I need to go and and I don't remember it off top of my head because Faust just kind of handles all that shit for you Um, which is an amazing thing, but it also means I know less than I should Uh, right at this stage of it, but Uh, so there is I don't I think I've decided that I we're not going to do caching for this first version So I'm just going to take it and I'm going to fart it out onto the onto the Kafka topic for you Um, and you can consume it and then it'll be obviously scashed inside the the database that clip is backed by Does that oh kind of answer Yeah, I'm tracking I'm tracking on No, I'm tracking that part um Can you tell me though What the name of that topic is I mean just as I start to write Uh, off handy. Those are just geratickets or ger you know like gerat I'm thinking judge an Eric name like tickets Okay, she won't okay for now just tickets. Okay. T.i.ck. It's make that a configurable field like I think you can see in here Like I try to extrapolate all the configs, right? And so maybe just make that topic configurable expose that and it can Fig that way we can change it later And it not be it not be something hard coded. I try I try to be smart about the things that I think we might change or might want to tweak or tune in the future And I expose those as configuration options Okay, and obviously I'm not telling you what to make like obviously this one I'm suggesting we make it a A configuration thing, but I'm not going to go through there and reject your commits because like you didn't make something a A configuration change I I'll just take that as that's technical that will go and address and and some of these things I'm just trying to do my best to to anticipate what we might tweak and tune in the future and I'm not expecting you to have that same level of insight So so um the the and then but we this should The so the clip plug-in tickets though. I mean this This mechanism where it gets into the you know, it gets registered as a plug-in inside the clip B um, I mean this this is This this scales horizontally right so these there's that is that how from a dev-op standpoint and deployment right there could be many of these Clip B E's in and of themselves have registered clip plug-in tickets in it There there could be that hasn't been fully tested uh, so just so so you know like the reason why I went with the plugin system is because our team is also responsible for Creating automated tooling across all of the uh, what we call src security and risk consulting My team also creates all that automated tooling and so I was building a Singular platform. So it really isn't makes sense to call it clip, but it kind of formed organically right constant building as their plans Refinement um, so I've made everything plug-in play that way we can reuse a lot of the existing stuff that we're doing for other web enabled tooling That src might need so I was really creating a platform in like this marketplace if you will Uh, plug-ins and so eventually the the other team members in like field delivery when they want to have something that goes and say hey I need something that can go in parts like an in-map scan or I need something that can go and Automatically generate reports well in the future when we're far enough once we get past this client portal They'll be other go cool. I install I pip install these plugins and now I have something that can parse in-map scans Right and give me a nice you know displaying all that other good stuff I don't need to necessarily you worry about all that. I'm just trying to explain why the architecture formed the way that it did Um, that that's the main driver behind the the plug-in system And then on top of that I was trying to anticipate because we were None of this stuff when we started to write this stuff none of the back end was there for any of this stuff And so I was having to write a lot of mock stuff Right because We did ship backwards out of my control We decided to go hire a front-end developer to go develop front-end stuff when we hadn't even really conceptualized the fucking back in Right, and so I'm like, okay, I need a plug-in system then because I'm probably gonna have to mock the versions of my API endpoints And then I need to make it simple to go and rip and replace those with the real things So the plug-in system at the time seems simple to me um, and it didn't take a lot of time to implement But I think one of the challenges you might run into is we need to figure out And this is where you'll have plenty of the work with Bryce right because the authentication mechanism Right, how do we make sure that we can access the right fields and we get we understand what a user's org is When they go and they re they access the the The ticketing API so that way they they only see their tickets does that make sense? Yeah, it does and we he and I already had a discussion about that because I know you kind of keep that out when you back on Monday But you know on that note I wanted to um Yeah, there One thing that seems to I think where where that Where you know, there's some changes that can be made but might even impact what What we're getting from you insights that you can get from the the gira API itself And maybe you're sending this and if you are I'm just missing it in the in the so on and so forth But so so for instance I see this client ID so that's the unique ID that would be the gira site for this case the gira ID I'm assuming for the ticket Um, and then the unique ID I'm going to assume that's our side maybe yes the you know unique ID Uh for the ticket is as you know if if we have a representation of it locally um But one of the things will Want to infer I think is is you know what Organization that belongs to um, you know that externally. I'm saying external yeah 100% Well, that's where way That's where the client ID that was intended by the client ID. Oh Bear mind things aren't named Things aren't named right because Tyler did these and Tyler has Yeah, this is this is like the end that's intended to be organization and we might change those attributes Like I'm not we like these aren't necessarily super fixed but before we start whacking away before you start whacking away at the models Give me some time to To get with what he's actually finally implemented in gira because even that wasn't done until like last week And so there was like there was like no there wasn't a lot of like I needed a way for him to be done So that and how and how do I get eyes on that like would he be checking that in somewhere? I mean because right that would be oh no that's in gira that that's So we have a sandbox environment gira and he was working to get that Ironed out and they just now started using it and he's already identified a whole bunch of things that need to change Which I figured would happen But we can probably give you access to gira service manager if you think that helps is don't don't go in there and modify things in that Well, it'd be read only if you did but I I wonder Okay, yeah, I guess so let me ask you this. I mean just right things are subject to change and you know I get that and you know, that's a process and things like that but um Just so that I can inform Oh, let me just see here because yes So what what I might do is Because I'm going to be canning my own Uh Representations of these in my own locally Kafka right. I'm really not gonna fire you up right now You know, I'm just I'm going to just fake this. I'm gonna fake um mock up the data in these cues for me to pull off and I'm gonna assume like you said client ideas the clients idea or the organizations idea or whatever externally And what I'll also do. I'm gonna let you know what I'll also do as I as I create my organization now here I'm talking about In the Django admin, you know, I create my ords um I I'll go ahead and because I don't think that he has this I mean rice I'll go ahead and can this client Ideas an external ID right for this for the or well so that key he started he started the org stuff and what He may not be connecting together is that's to make things simple. That's probably what we should be using for the the ID right however He's built it into the the authentication mechanism to be able to that ID that he's using Right now. I think he's using an int I've requested that he changed that to you ID before right yeah He is that he's definitely doing that right now for the for the Persons or the users He is the UI you know you ideas using right now as well, but which he probably wants to change is the cognito ID of the user but it's a you you ID. Okay, so I'll circle back with him and just make sure What I'm saying is just get the ball rolling on his side the synergy there Yep, you know, I'm not a right now. I'm manually onboarding those ords and I'm sure there's going to be a Different process for that, but just that he's aware of You know, so we'll be writing obviously the tickets and the ticket and I'm going to get to this in a minute But to the ticket you know some association Between the ticket. I mean really should just be a one-to-one. It should be a property of the ticket which it is right here You know on the database I'm talking about Of the client ID and then of course now he's hashing out the relationship between users and the organization So I think we got a good handle on that and I think he's working through that But yes, I just want to make sure yeah, I will sync up with him and make sure Because I think there is coming down the road a you know an organizational onboarding Not the way that I'm doing it and the way that he is figuring out that some you know yeah But just be aware of kind of the conversation you and I are having now on that no I think that'll make it easiest if we use whatever ID That he's generating to be able to track users to what org they belong into versus because then we have to create another mapping If I use a different ID and so I'm to me that simple now agree now the problem comes into play is What happens when a sock in it is create the ticket on Giro Do they have to hand jam that ID or do I need to or should I be providing him with a separate interface go fucking open tickets because that would suck Uh and and I don't have a good answer for that yet Um because there isn't one because we're we're kind of I think we're kind of limited but Eventually that won't matter the Giro service desk won't matter themselves because they will be using what a product called swim lane That's our sword platform and I can do a lot more stuff with orchestration for them inside of that sword platform to be The open tickets and all this other stuff But in the short term yeah, though though because that that ticketing information that we get out of Giro when a When a sock in this opens it on behalf of the user will have to contain that org ID and but that org ID should be coming out of Clip right because that's how we're tracking users to an org that way it's the same agreed and we're not doing stuff I think though. I think well I think we're saying the same thing in the sense that like whatever that yes, whatever the Domain ID is that's clip ID. Yeah Um, I just want to make him aware and Just as he's aware of the from the user standpoint and although he's making it to primary key and maybe that changes He's using the cognito ID. I just want to make him Oh, where of and he's probably is that's the name that maybe he's talked to you about it But but this this idea of this client ID that represents the organization External it's external ID. I just need him to carry that because obviously that's how I'm going to query As I bring in these tickets off of the queue right as I'm going to write this To that organization, you know, this is my identifier, right? You're not key. You don't know on your side Well, I don't know. Maybe I'm wrong about this but you you're not concerned right you're you're not concerned with the Clip ID The organization as you're writing off a zero right you're just Bring it in and reflecting the and unless you're doing some are you doing some additional things? Sorry Maybe I'm presuming something I shouldn't be presuming here. Are you Are you doing any additional domain work in the JIRA SM? You know that would require you for instance to hook up to a You know to the the data bit of post-gress database and you know do some things like that And so therefore you will be writing the you know our organizational ID. Let's call it our organizational ID In the message that makes it into the topic. Do you shoot? Does that make sense what I asked? Yeah, so if I'm trying to write organization ID So for the instance of what we're looking at right now client ID, right or a guide. We're gonna call that org ID Yes, what he whatever we're wanting so so right because we have we have multiple organizations that we're monitoring each or those organizations Have users that are gonna be attached right so correct those user IDs need to be mapped to that org ID That org ID that we're using should be attached and associated to every one of the tickets that are associated with that org Now JIRA itself won't have won't be connecting back into our post-gress database eventually The idea is we're still gonna have JIRA but no one's gonna log into it They're gonna use a product called swim lane that's gonna orchestrate everything on their behalf Right and so that org ID Long-term I don't like it just however he's doing it whether whether we're deciding that we're gonna use whatever Cognito comes up with or I think the last time I talked to him I thought he we were bringing all that inside of Django because there's a possibility That in the future we might even remove cognito and move go to a different product sure because cognito is not yeah Yeah, cuz cognito is not multi-region It is single region which means when there's a region outage NAWS right It means nobody can log in So right right yeah Yeah, I've ran into that myself with other clients for sure The so I mean it was my following what you asked correctly You are I guess what I'm saying is is though like This client ID that comes out of the queue is not You know is not the you know unique identifier that you're talking about that's in Django or in our or in our post-press right that that's gonna be the internal one that's just created on the tables Some I doesn't matter for the UID whatever. It's just generated what I'm saying is is The Because maybe I'm not tracking maybe I'm not tracking this I'm saying This client ID and then I'm really I'm talking about this client ID. So I'm not talking about I'm talking about this unique identifier Here for this That's what I'm what I'm trying to get at is it's the word that I would use the adjective I'm using is is external That's the external ID of the client it isn't the one that that we make associations between organizations and users Right because no it's not external. I would argue is not external. Do you think it needs to be external? So this is the idea you're okay, but I mean I guess I don't but Uh wait a minute. No, I do have questions about that wait a minute because Because that's coming from Jira is it not like that's the Jira or How are you but that goes back to my question? I guess I just I didn't understand it. I didn't know I'm not understanding You're you're you're subscribing in whatever fashion, you know web hooks or you know rest whatever you're polling whatever it is Um, you're you're getting the things that you want from the Jira SM You know, it's going to be JSON you're bringing it in you're pumping it into these topics and cues and that um you And but that I mean and there's some identifier right for whoever owns um whoever owns Clip 143 right that's a ticket that comes across it's Jira, you know, the it's title is or whatever it's a unique identifier Hypod 143 right, but there's an organization right in the whole hierarchy of Jira behind that right? It's got it like that, you know some cluster that it belongs to there some some or you know entity Um, are you saying that is now that that is not what you're putting that yeah, it's not coming from from Jira The idea idea is that our our sock analyst should not Be creating a lot of tickets that are going I mean, I guess all the tickets are creating Go right now. So when clip is launched the ideas that the majority of the tickets that are created are actually coming out of clip itself So it's coming out of the thing out of this ticketing API and so that information is Swim Lane is going to manage So eventually swim lane will manage all the things so the problem right in a sore platform as you can typically only hold about six months Of data in there before you start getting impacted. It's just the size of the database and it's doing more things and managing tickets right it's automating entire sock processes and keeping historical records all that and so I need you have to have or I need an external ticketing platform that you're syncing information to right that acts as your long-term memory right? So that's basically at the end of all of this once everything's in place and where that's year that's like a year down the road Gira eventually hopefully no one has to log in there unless something's broken Right and then we're having to fix it or we're having to make some architecture change because maybe we need some extra fields on a ticket or something like that otherwise everything will be managed With inside of swim lane from a sock analyst perspective Yend users like our actual Clients that were managing their infrastructure for they'll go to the clip Port to the client portal and they will open tickets from the portal now how that's actually working right is what you're writing here That that front-end right sends requests to the bank and hey we need a new change case Right and all the information is captured by the client and in that new ticket is sent across to my Service that I'm writing that's actually doing all the interfacing with with uh I just completely switched around like yeah, why you're fine with that There's a little bit of complexity the nuances that I'm building here because of the bigger picture, but Okay, so I'm really Okay hold on so I let me just switch my gears and flip it the workflow right now is Is I'm writing I'm writing a rest piece that is taking I'm a ticket of some you know a change case a health incident of what sums of work and I'm one of the things I'm absolutely doing is sending it out to you Yep, you're dropping it in the queue and Then I will need two cues now that I think about it because we won't want to use the same queue that would be confusing It would what do you mean pick tell me what those names first? Well because I originally I just said a ticketing queue But that only where that's that's only one direction. We'll need another one for you to send So like maybe Yeah, do I okay so you want okay so let's talk about that okay, okay, so you so it's unfortunately on board there you're saying I think I understand the piece of where I am pulling from your Uh from your topics But I'm also pushing another and separate topic now got it um to you so you can make changes to zero I go and make changes. Yeah. Oh, you got to worry about is dumping the information onto the queue and I will handle the rest Yeah, that's all you gotta do and And in the same room that you were expecting you're expecting in the manner You know, whatever form the JSON is of these models that that's what's called yeah essentially right Yeah, I'm not wanting to make things difficult for you so whatever whatever in these models will probably Change a little bit as we go through the process to account for the changes Tyler's making but then whatever minor nuances I'll serialize that on my end to make sure I put it in the format that you're in need it Right, but I'm I'm basically I'm how you get and I'm how you create tickets and I'm how you receive changes right because obviously right now Swimland doesn't exist so for a sock analyst to interface with a ticket They have to go to cheer at this moment and so changes will in fact becoming out of cheer a hints the the web the The web hook right so that way anytime they modify ticket I get notified instantaneously of it and then I send you the the updates right like here. Let me ask you a modification to the ticket Huh Oh, let me ask you one more thing about that to though. So how on the um What what is the Or is this the first pass that we're doing here? What is the mechanism by which So inbound to me from my perspective inbound to me off of your topic um What is the mechanism by which we alert the in user Or is there is there is there mechanism to do that like is there a need to or is it just There is a need to There is a need to for a notification API You're right, right, so I'm sort that basically will email them but Then Hasn't really been discussed yet Oh, yeah, but it is going to be something we don't figure out mm-hmm got it got it um And Okay, and then let's let's talk oh, so it's been a migrations real quick We we might be able to use like just real quick before we move we might be in a short term be able to use like Gira to send those notifications out in the short term so we meet our release date Long-term that's got to be something different entirely because we have more than just that notification to send out in the future But they'll need to be a notification system of some sort, but I don't want to I'm trying not to money the waters But still try and paint the grander picture Actually um now I see here. I don't I admit I'm missing this but I don't see really any of these tickets as far as a You know on the schema a table um Except this health incident so it's a part of this work to maybe get a hunt case A security incident get those modeled to as well and in a migration or am I missing now? Maybe I'm just missing this somewhere am I am I missing that or well, so all that should be those every one of those models should be a table Oh, okay Well, or maybe they're hold on Yeah, they should be a table. They should be a table. It should be a table, but I guess I don't Well, if you're depends on which migration you're looking at. I'm not familiar Django my work on the server side with Python has been most last-related So you know jingo the jingo API is you know, there's even the runtime there nice and something I'm learning but Well, and then of course I'm doing it all fucked up for you. That's gonna make it awesome for you to learn Ha Good you go and you try to learn Well, you try to learn normal Django and you're like plug in what oh yeah, I'm I'm bastardized the whole day But I mean right I see you modeling here though, right? This is this is the table that this is the backing model That for health incident like I know I don't see anywhere else like you doing that for I don't change with change case or whatever I see that's it well That means did you look in the initial because because those those migration I don't know what you're gonna have Yeah, yeah, yeah, initial because there's multiple migrations so every time in these migrations were created They're bidding on how there's nothing to do to me it changes. Yeah, okay, so there's a lot of walk you through it real quick So there's nothing in it you saw that There is an initial is just a my model which oh yeah, it's delicious Uh, you quickly delete Here wait, I'm gonna get there. There it is you delete that on 74 But so you've got comments that's those subclass is okay. That's fine right you've got that oh, oh wait change case I said I see one At the I still feel like you missing that couple here though. Oh you got now if we go to three Health incident you got some time stamp modifying fields here to get some you know So some time stamps and you know, yeah, you got you make some field the one-offs But I know you seem to think I'm missing you maybe I'm Yeah, so you don't have to write migrations the migration files that that's a Django thing So Django auto creates those all you got to do is write the models and then when you run Django you do you And then of course I wrap the command line which makes it even more interesting for you So that's if you go and you won't see it here But if you go into the clip be and you go into the CLI folders You'll see where I'm wrapping the actual Django command line to provide a unified command line Because yeah, I'm being helpful Some of those I'm I wonder but um I Rapping and so you run and make migrations right which actually creates migrations these probably maybe I shouldn't have been committed I could have probably left those out but I I grabbed them but really what matters is the migrations That you make when you when you incorporate everything together and you actually run the make migrations and then you run The the apply migrations command and then it'll actually alter the database So you don't have to write these anything in the migrations fully you don't have to write now sometimes Sometimes if you're doing really interesting shit um that but it has to be but it's like a really really unique specific Use case I don't ever imagine that we're running to you might have to modify The the migrations to make it work if you've done something really super crazy But not other things that we're doing fit should fit that use case Okay, so as I'm looking here in the um Uh and and by the way we kind of went over that yesterday. So yes, I'm familiar with Uh some of the commands you need to do if you make any changes uh related to the databases, you know, you definitely need to run your migrations the uh But as I see here um So and my reading is correct a lot of these are just kind of stubbed right now and you know, we're gonna do the heavy lifting to get that uh or maybe not maybe it's a finer detail there but to actually get these um, you know written and you know, so they're written to the database So you know, we're obviously going to update what we're doing on the database and then for for every one of these Well, I know that's like that's a great question. I'm about to ask um for For these rest endpoints um Um are we What are you being notified of you you now you what am I sitting to your queue? Is it just anything that's um That's uh update or You know cudd and create a updated delete um You're not okay, so just cudd level stuff Yeah, yeah, so anytime you're like making a change or delete And anytime you would be making a change to the database that this is tied that this is backed by That's dealing with any of those tickets That should also be sent to me Right so I can reflect that in the gira instance But I'm not but as far as querying and getting it's enough to return what we have right I'm not way that's not something you don't have a digital information No, you don't need to ask me for me. I mean short of whatever but was short of order around do obviously Short of whatever I'm doing is a subscriber of your you know the other topic Well, I'm never saying appropriately. Yeah, I'm telling you to go Yeah, yeah, my service is telling you you don't have to ask my service for nothing my service We'll just tell you here's enough to just take a change Yeah, I'm uncertain. I'm understanding the picture now got it. I got that Yeah, I think so think it's a legit event it's an event Driven architecture that we're creating here. You're just caching stuff as well Right, so that way you don't have to go and ask me to go get stuff You're you have it local and we need to do some other mappings You know maybe in the future we'll do away with it But for right now that's what made sense when I was throwing it all together So you've got the you've got that database, but otherwise yeah You only need to tell me when a customer makes changes to the tickets or creates a new ticket Or somehow if we expose a deleted ticket right they I don't know if that's in the cards yet But I there's probably there's a mocked endpoint. There's an endpoint for it But and then I will just tell you when tickets are changed or created on my side right and so we're basically You're just telling we're telling each other when shit's changing So exactly and so but and for that matter. Okay, so let me Let me ask you this just thinking to head on that So Receiving from you if I received So here's here's I'm going to go through a couple scenarios some cut scenarios So I don't have it and tell me if these are even possible I have a from you I receive a ticket and now I go pull of the database for a unique ID For that for now at least maybe that changes, but let's you for now. Let's just look at this Um, I go pull the database for that ticket unique ID. I don't find it So first of all is that a scenario? So now I don't I don't have record of something that you're sending me is is that possible? Yes, yes, uh that is for the time being that is a possible scenario that you would get a net new ticket That would happen if the sock analyst Went into the gira sm instance and created the ticket manually and and what so therefore the would I see a unique idea or would I be like oh that's no Well, we didn't have it. It's new. Yeah, that'll be Yeah, so I'll send over the uh and we might need to add and we might need to add some more fields I will send over the ID that's coming out of gira Um, and we will need that ID right so we're going to need to store that but for you you should look and and so you there There there's a couple of different methods here and we probably need to talk about it You can either look and see if you've seen that gira ID which will need to be recorded or you can see hey, you know, this doesn't actually have Uh unique ID in our database like I can't this isn't existing anywhere so then I know I need to create it So I and I probably just I probably said that really confusing and I apologize Gira has a unique ID. Yeah, and we'll need to we'll need to track that because that'll be how I go and reflect updates that ticket Because gira won't doesn't know anything about clip and it it'll never will because it just you know, yeah exactly exactly so let let me ask you this um I'm tracking there and we had this we had this kind of bit of this conversation a little bit earlier this idea of You know of these external IDs for whatever these things are if it's an organization if it's a ticket if it's a person if it's a whatever You know, whatever it is there's an external ID for that. I'm just wondering if just in here like I'm just spitball I hear but but I mean what would it be who us to You know create an external ID let me finish my thought array On these things That way You know it really only grows it never shrinks these IDs That way that you know if if if if an entity that we understand now talking about our internal Idea of clip ID. I'm gonna call it clip ID the clip ID of this thing. Well that never changes But you said you know if what if we went from you know, I well it you know, it's um regent specific With cognito and so on and so forth, you know, maybe maybe we don't land one externalize or maybe they move to different gira to something else or maybe you know You know, maybe we have uh, maybe we should have an array of external IDs for these entities Just don't out that that Not asking yes or no on that but is it would that be helpful to keep it more resilient in case of Migrations or changes in plans, you know architecturally Well, so I'm thinking I'm thinking what I need what we need to do here is we need to we need to add another attribute To the base ticket right because the you the unique ID. I'm thinking should probably just be the primary key Right and then there needs to be that external ID Right, that's the gira and in this particular case it is the We'll say the chosen service provider For the ticketing system in this particular case. It's gira right that'll be the gira ID that goes in there But to clip it's just the external ID right now. It'll be coming across and you'll save that but the actual unique key From the from this plugins perspective is going to be it's put its primary key in the database. Yeah And that you just said probably could be ID, but we'll just call you unique ID right now Yeah, I mean, there'll be yeah, there's gonna be so in Django the you you do inherit the ID field for free You can rename that but you have to call it out in here. We can just drop that to ID And then make that a you you ID before So I so you'll have to go and make this a you you ID before numbers will and we'll just track everything that way I'm just not a huge fan of ints For primary keys. Don't ask I thought it's probably some I probably need to see a counselor Well, okay, so I so I'm gonna change this and I don't think I've ran only Well, maybe after in migrations, whatever, but yes, I'll get that kicker care of I'm gonna start a live e here that makes sense and client ID for and I'm gonna change this is because that just for the client the client and that's an I'm gonna change it also because you're gonna make that you like We're gonna make you brain you should be getting that from Bryce From yeah, and I'll talk to him about this after after our media and do appreciate your time here So let me let me go back to what I was saying which was okay So so let let's go through our code scenarios there. So I something comes off What did you say just a land on would I would definitely see an external ID? That's true But would I see an ID or would that be null for so you know, so it would be a new ticket to me So almost okay, so now that we've we've settled on this bit of this this slide architecture change You will never see an ID number from me Did I have no I have I don't know I'm not storing I have no I'm not seeing now this is what but but I'm gonna here I am gonna judge on the code crazy because I'm gonna go back to this client ID though couldn't couldn't that also be no Could it possibly be no the debt There's there's a there is a possibility that it's no but that also means that I didn't I didn't reject it Right which which to me if right that ticket to me to me That Gira and it's so if you ever get a client ID if you ever get a ticket to do have a client ID that means something fucked up Right that that's what it means to me because that client ID is mandatory you have one Whether it comes from Gira whether it comes from our system and I'm talking about new here Yep, you're gonna find a way to resolve that okay, right even that new yet should have something in and so I will be doing validation checks Inside the service to make sure that's all happening in Gira we will try and do our best to configure it So that way those fields are mandatory And then for some reason you still get one and it doesn't have an ID you just need to reject it Right if it doesn't have a client ID you just drop it I'm probably need to log a message somewhere a log an error right don't obviously crash But log an error to the logging system and then drop the ticket Um and so okay, so so so so it's so in the case yeah, so I'll always get an external ID for things from your from your external ID and the client ID You'll always have those and it caught a deal right and so yeah go go match those up eternal ID doesn't match It's new to me then it's new and so I need to go create that fun that's great now so update Makes sense you're gonna send me that it's gonna. I'll have an external ID probably still may not have an ID Maybe I do maybe I don't but I can at least uniquely identify it and and certainly if I found it then we have a representation of it's an update got that yeah now Now that's talk about delete Let's talk about delete what does that look what's that payload look like Coming in right it's an external ID, but obviously I need to know to get rid of Right so what does what's that payload look like is it just the external ID Uh and the client ID or we're not are we representing actions at all in the payload like you know create update Or delete or you know or am I signaling it based upon just an external ID and a client ID and it's like oh wait a minute I only got two fields he wants that deleted that's that's a goner, you know like there's no it nothing to to write and you know some saying So you'll probably so that I don't know 100% exactly what'll be in there obviously you're gonna have the external ID Right, I don't know 100% what the payload all looks like from the from the webhook right because it you'll get 100% of whatever is sent in that webhook. I'm just gonna send it to you and then let you figure out what you know Right, I'm not trying to hide information from you. It doesn't cost me anything to send extra stuff across the Across the line and in you will get it and then take what you need from it and then Just do it. Look can you piece a couple of pieces together here for me So you talked about that you have a sandbox now environment for Gira and that somebody whose name I forgotten is is working on The aspect but basically gave okay that gave you an a That you know some of the shit is that what we're is that what he's doing right now is actually so I've got a You know, I've got their their meaning Gira's Representation of other organization a ticket and so on and so forth is the same box environment away for him saying well Okay, by the time I want to get by the time I want or how if he's given it to you or you're taking it from him Whatever but when Josh is involved with this Gira SM project By the time that he you know gets it this is what it's going to look like That are at least almost completely right. I mean, I'm kind of obviously what I'm Right, he's kind of giving it to me. Yeah So I guess what I'm asking I guess what I'm getting at is wait. I mean what am I getting at? What I'm getting at is on the delete then right so you're That seems like that's going to be hashed out like what does that look like like if somebody if your client delete goes to Gira and Delete you know doesn't go through the portal Oh, they did the client. Yeah, the client has no way to get to the Gira service manager without or that So it would be a sock and say when he deleted some analyst got Okay, so they did that and so So Figuring out what that is and then you know is part of what he's doing and you know he's working with you with that um And then that shape like you see I'm just I'm really narrowed in on those words that you said you said hey I'm not trying to hide anything for me. I'm really just going to pump it into the into the topic there So it's like almost like that shape is predetermined of this somewhere someone's making a decision right it's not Gira Right Gira's now maybe That's not official, but that's someone saved the schema Out of it that looks like probably everything I'll end up having so you'll end up with a bunch of like base stuff because Gira Is opinionated and what I was looking for was if if it actually oh it does look like so we're here So if I look right here, it actually tell me issue created issue updated. So I'm imagining there's probably like an issue deleted Right, so this is out of the web hooks for Gira So Gira service manager has backed by just plain Gira Um, Ryan I imagine I'll get a lot of the same thing when I iterate because I because the first time my connector Comes on It will iterate through all the tickets that are in there and it'll send those over to you And you're expected to go I don't need to do anything with this Right and just drop it or you might because there's no way for me to know whether or not I've sent that over to you unless I'm caching and we're not caching Uh, they're in no way You're probably caching just for a little bit in terms of just how How the life of a topic in the queue but whether or not so comment is caching process yeah Kafka caches it until you use it right and then it ages out right because you won't see it again But technically it's there you can access it But then there's a G there's a job policies and stuff like that But yeah, but by the by the default config that we've done I will send it over my service isn't caching it to know whether or not I've sent this exact topic to this exact issue event to you before Right um, but you'll have you I think by the fields that are in there you'll be able to know um What it is when it's coming across via at least a web hook um and then And then you can and and when I'm iterating over things and I'm sending it to you um, then you can There's some things that I need to figure out because there's a potential scenario that the service restarts and in the process of its restarting somebody Went and and modified a ticket real quick Um, and then it came online and then it's gonna iterate through all the the existing tickets That are open right? I don't necessarily Well, there's a potential that somebody close the ticket to I need to think through some of that Well, but but this now I didn't see this webhooks api but now I'm understanding here Maybe it is like you said admit me the events array, you know that This aspect that's on my screen right now. Yeah, would be important to you know, yeah heck that would that would tell me You know like that's what I'm looking for So if that gets brought across that or in some way in some fashion Yeah, it should everything it's in there. Okay, whatever I'm getting I'm gonna give to you. So Okay, okay, okay, okay, okay, I'm gonna look over that this document here because I didn't look that again Um, okay, so that's I think I I think I have And under standing Have this yes, I think I think I have Enough to do some damage um, and I will Yes, if you have though Josh if you have um You know just an example message out there like it you know of like you know Disorder or someone other for a ticket. I'm talking about literally the payload. Oh, yeah, no, I don't I don't have that yet the closest thing I have is the thing I just sent you is the g-roll So where did you send it to me? That was it is like I sent it to you and slank okay But I can't promise you how great that is because that I just pulled that off as somebody else's get so But I don't have examples yet. I'm hoping to buy hopefully Monday because I'm gonna spend this weekend working on the connector, but Um, and then I should get it. I mean, it's enough for me you you understand where I'm from like I just Did just even box like right we'll change it. It's not a not a big deal But I understand there probably be a body in here because this is exclude body false, but no go up go up to the go up one go up one See that link I sent you I I slanker's just look on that Yeah, that that is an entire webhook payload Oh, there we go. So you're gonna give me this thing. I think so I think so so many You know Stuff this was three years ago So if it hasn't changed too much from this story. Yeah, yeah, no, this this this works Yeah, this this will this will well in the end with Uh So oh just hold on. Oh darling To give me that and then I need to marshal that into this and then wait a minute to write you I know from the end that because this is what I'm gonna get right this so I mean for nowWe're saying this is what I'm gonna get. They may change. This is what i'm gonna get right this it's a little JSON And I need I need to make it it make it so right make it into this clip model, right? Yeah, that's that's something I'm gonna need to peel off and You're saying the client that he's gonna be in here somewhere right? You're saying I'm gonna have to so there's gonna be things I have to add because this won't have because there's custom fields that we're adding to Gira That obviously isn't gonna be reflected in this person's web hit payload, but we'll be in reflected in hours So just keep that in mind right because we can't add custom fields and so custom some of these are gonna be custom fields That we're gonna send to you so like like this account ID that they have in there that user account ID Probably not gonna match right because they're not gonna actually our clients are gonna have actual user IDs on Gira So you can ignore some of that data Yeah, so I will and I can probably do I can probably filter stuff for you when I send it across and so just well Well, I'll tell you what for now what I'll do is I'm just gonna treat this as the gospel just so that I can get you know You know some work done on the inbound And and look I understand you're gonna change it and probably Monday you'll change and so I'll update where I get these fields Like right now erroneously So I will erroneously pick these fields off for now just just to have something For the fields you know an absence of that and then I'll just modify that as it comes across Um and what I'm gonna do with my life the other thing is the other thing is um Okay, so but let me just when I send out to you when I send out to your queue What is the shape that you expect is it back to this or do you just expect expect a serialized version of the ticket So for right now I'm thinking I just need the serialized version of the data that you're you're actually saving and then I will take care of the rest And you know what I'm gonna do I'm gonna throw this out I'm going to add an event type and an event to it an event array So you know What it's for so we'll communicate our intent Over the event whether it's an array. I like that. Yeah, so matching similar to what we get out of the webhook I like that exactly exactly. I'll do that so you'll get and as soon as I figure that out I'm gonna send that I'm gonna send you a JSON version of that and then you can criticize it or just use it and then So that you can do your work, you know or pump it in on that side will be your inbound For me. Okay. I have enough to break this so I will start working On a brother hand. Yeah, this has been very illuminating You know catch it on just what you were thinking and things like that and you know just enough for me to have You know really inputs and outputs, you know inputs and outputs I that's what I need with respect to you and then everything else is just really rest logging and you know Writing to a database and and that kind of thing so yeah, you know no problem over there. Okay. I will let you go Josh I appreciate it. If anything, I'll just reach out to you over chat. All right sounds good, buddy. I appreciate everything Don't I appreciate you for you to reach out if you have anything. I'll get to you soon as I can and I appreciate everything that you're doing Yeah, thanks. Thanks. We'll talk you all right. Bye\n"
     ]
    }
   ],
   "source": [
    "result = model.transcribe(audio_file_path)\n",
    "print(result[\"text\"])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-15T02:46:40.215826300Z",
     "start_time": "2023-06-15T02:26:07.048032200Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Chunkify"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def split_text(text, maxsize=3000):\n",
    "    # Split the text into individual sentences using regex\n",
    "    sentences = re.split(r'(?<=[^A-Z].[.?]) +(?=[A-Z])', text)\n",
    "\n",
    "    # Initialize variables for tracking chunk size and current chunk contents\n",
    "    max_chunk_size = maxsize\n",
    "    current_chunk_size = 0\n",
    "    current_chunk_contents = \"\"\n",
    "\n",
    "    # Iterate through each sentence and add it to the appropriate chunk\n",
    "    for sentence in sentences:\n",
    "        if len(current_chunk_contents) + len(sentence) <= max_chunk_size:\n",
    "            current_chunk_contents += sentence.strip() + \" \"\n",
    "            current_chunk_size += len(sentence)\n",
    "        else:\n",
    "            yield current_chunk_contents.strip()\n",
    "            current_chunk_contents = sentence.strip() + \" \"\n",
    "            current_chunk_size = len(sentence)\n",
    "\n",
    "    # Yield any remaining content as its own chunk (if there is any)\n",
    "    if len(current_chunk_contents) > 0:\n",
    "        yield current_chunk_contents.strip()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-07T02:44:37.027396900Z",
     "start_time": "2023-06-07T02:44:36.980101500Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "outputs": [],
   "source": [
    "chunks_of_text = list(split_text(result[\"text\"]))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-07T02:44:37.804889900Z",
     "start_time": "2023-06-07T02:44:37.776775800Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "outputs": [
    {
     "data": {
      "text/plain": "10"
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(chunks_of_text)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-07T02:44:38.654298Z",
     "start_time": "2023-06-07T02:44:38.613063700Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "outputs": [
    {
     "data": {
      "text/plain": "26444"
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(\" \".join(chunks_of_text))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-07T02:52:47.257412300Z",
     "start_time": "2023-06-07T02:52:47.235408100Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Convert to Notes"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Build Chunk Summaries"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "sum_results = []\n",
    "count = 0\n",
    "\n",
    "for chunk in chunks_of_text:\n",
    "    chatgptPrompt = '''Using the below meeting transcript chunk, create a summary of the meeting chunk.:\n",
    "{}\n",
    "'''.format(chunk)\n",
    "\n",
    "    completion = openai.ChatCompletion.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        messages=[\n",
    "            {\"role\": \"user\", \"content\": chatgptPrompt}\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    sum_results.append(completion.choices[0].message.content)\n",
    "    count += 1\n",
    "\n",
    "    print(count)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-07T02:51:04.447306Z",
     "start_time": "2023-06-07T02:49:51.900849400Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "outputs": [
    {
     "data": {
      "text/plain": "5302"
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(\" \".join(sum_results))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-07T02:52:07.501886400Z",
     "start_time": "2023-06-07T02:52:07.448349600Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "outputs": [],
   "source": [
    "sum_chunks_of_text = list(split_text(\" \".join(sum_results)))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-07T02:54:23.702377Z",
     "start_time": "2023-06-07T02:54:23.685388600Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "sum_results_second_pass = []\n",
    "count = 0\n",
    "\n",
    "for chunk in sum_chunks_of_text:\n",
    "    chatgptPrompt = '''Using the below meeting transcript chunk, create a summary of the meeting chunk.:\n",
    "{}\n",
    "'''.format(chunk)\n",
    "\n",
    "    completion = openai.ChatCompletion.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        messages=[\n",
    "            {\"role\": \"user\", \"content\": chatgptPrompt}\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    sum_results_second_pass.append(completion.choices[0].message.content)\n",
    "    count += 1\n",
    "\n",
    "    print(count)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-07T02:54:59.889336800Z",
     "start_time": "2023-06-07T02:54:36.875827100Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "outputs": [
    {
     "data": {
      "text/plain": "1644"
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(\" \".join(sum_results_second_pass))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-07T02:55:24.854700300Z",
     "start_time": "2023-06-07T02:55:24.760811600Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The speaker proposed a turnkey security solution for Fortress Energy with professional services and compliance with TSA SDZC directives, divided into four phases with set timelines. The team discussed the access and architecture of the cloud piece and set up a proof of concept for secure remote access. Michael offered to send more information for a meeting on Wednesday and deployment plans were discussed, aiming for SRA by July 1st and active directory integration & identity management by July 19th. Technical requirements, firewall rules, and port lists were discussed, and the group plans to coordinate project management resources and submit a proposal and a partnership agreement.\n"
     ]
    }
   ],
   "source": [
    "chatgptPrompt = '''Using the below meeting transcript, create a succinct summary of the meeting:\n",
    "{}\n",
    "'''.format(\" \".join(sum_results_second_pass))\n",
    "\n",
    "completion = openai.ChatCompletion.create(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": chatgptPrompt}\n",
    "    ]\n",
    ")\n",
    "print(completion.choices[0].message.content)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-07T02:57:07.352150100Z",
     "start_time": "2023-06-07T02:56:58.451601400Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'gensim.summarization'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mModuleNotFoundError\u001B[0m                       Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[78], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mgensim\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01msummarization\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01msummarizer\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m summarize\n\u001B[0;32m      3\u001B[0m \u001B[38;5;28mprint\u001B[39m(summarize(result[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtext\u001B[39m\u001B[38;5;124m\"\u001B[39m]))\n",
      "\u001B[1;31mModuleNotFoundError\u001B[0m: No module named 'gensim.summarization'"
     ]
    }
   ],
   "source": [
    "from gensim\n",
    "\n",
    "print(summarize(result[\"text\"]))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-07T03:40:49.642989800Z",
     "start_time": "2023-06-07T03:40:47.602464500Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
